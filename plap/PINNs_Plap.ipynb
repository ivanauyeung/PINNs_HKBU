{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Solving the p-Laplacian Equation with PhysicsNeMo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This notebook demonstrates how to solve the p-Laplacian partial differential equation using Physics-Informed Neural Networks (PINNs) with the NVIDIA PhysicsNeMo library.\n",
        "\n",
        "PINNs embed the physics of the problem directly into the neural network training process. The network is trained to minimize a loss function formed from the PDE residual and boundary conditions, effectively solving the differential equation without requiring training data from other solvers. More information about PINNs can be found in the <a href=\"https://www.sciencedirect.com/science/article/pii/S0021999118307125\" rel=\"nofollow\">paper</a> by Raissi et al.\n",
        "\n",
        "You can refer to the <a href=\"https://docs.nvidia.com/physicsnemo/index.html\" rel=\"nofollow\">PhysicsNeMo User Documentation</a> for more examples and API details."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Contents of the Notebook\n",
        "\n",
        "- [Solving the p-Laplacian PDE](#Solving-the-p-Laplacian-PDE)\n",
        "    - [Problem Description](#Problem-Description)\n",
        "    - [Case Setup](#Case-Setup)\n",
        "    - [Step 1: Creating the geometry](#Step-1:-Creating-the-geometry)\n",
        "    - [Step 2: Defining the p-Laplacian PDE](#Step-2:-Defining-the-p-Laplacian-PDE)\n",
        "    - [Step 3: Setting up the Domain and constraints](#Step-3:-Setting-up-the-Domain-and-constraints)\n",
        "    - [Step 4: Adding Validation data](#Step-4:-Adding-Validation-data)\n",
        "    - [Step 5: Hydra configuration](#Step-5:-Hydra-configuration)\n",
        "    - [Step 6: Solver and training](#Step-6:-Solver-and-training)\n",
        "    - [Visualizing the solution](#Visualizing-the-solution)\n",
        "\n",
        "#### Learning Outcomes\n",
        "- How to use PhysicsNeMo to solve PDEs using PINNs\n",
        "- How to write a custom PDE (the p-Laplacian) in symbolic form\n",
        "- How to parameterize the PDE (varying p) and train a single network\n",
        "- How to set up boundary and interior constraints\n",
        "- How to visualize and compare results across parameter values"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Solving the p-Laplacian PDE\n",
        "\n",
        "### Problem Description\n",
        "\n",
        "The **p-Laplacian** equation is a nonlinear generalization of the standard Laplace equation. It arises in many applications including non-Newtonian fluid mechanics, glaciology, and image processing. The equation is:\n",
        "\n",
        "$$\\Delta_p u = \\text{div}(|\\nabla u|^{p-2} \\nabla u) = 0$$\n",
        "\n",
        "In expanded form for 2D:\n",
        "\n",
        "$$|\\nabla u|^{p-4} \\left[(p-1)(u_x^2 u_{xx} + u_y^2 u_{yy}) + 2(p-2) u_x u_y u_{xy} + u_x^2 u_{yy} + u_y^2 u_{xx}\\right] = 0$$\n",
        "\n",
        "For numerical stability, we use the **normalized form** (dividing out the $|\\nabla u|^{p-4}$ factor):\n",
        "\n",
        "$$(p-1) u_x^2 u_{xx} + (p-1) u_y^2 u_{yy} + 2(p-2) u_x u_y u_{xy} + u_x^2 u_{yy} + u_y^2 u_{xx} = 0$$\n",
        "\n",
        "**Problem Setup:**\n",
        "- **Domain:** 2D square $[-1, 1] \\times [-1, 1]$\n",
        "- **Boundary condition:** $u(x,y) = |x|^{4/3} - |y|^{4/3}$ on $\\partial\\Omega$ (Aronsson's function)\n",
        "- **Parameter:** $p \\in [2, 10]$ as a training variable\n",
        "- **Validation:** Compare solutions at $p = 2, 5, 10$ with the Aronsson solution\n",
        "\n",
        "The **Aronsson solution** $u(x,y) = |x|^{4/3} - |y|^{4/3}$ is the exact solution for the infinity-Laplacian ($p \\to \\infty$) and serves as an approximate reference for large $p$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Case Setup\n",
        "\n",
        "Now that we have our problem defined, let's look at the code required to solve it using PhysicsNeMo. The library provides APIs for parameterized geometry (CSG module), symbolic equation definition (SymPy-based), and advanced neural network architectures.\n",
        "\n",
        "<h4>Note: In this notebook, we describe the contents of the <code>plap.py</code> script</h4>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "```python\n",
        "import numpy as np\n",
        "from sympy import Symbol, Function, Abs, Rational, sqrt\n",
        "\n",
        "import physicsnemo.sym\n",
        "from physicsnemo.sym.hydra import instantiate_arch\n",
        "from physicsnemo.sym.hydra.config import PhysicsNeMoConfig\n",
        "\n",
        "from physicsnemo.sym.solver import Solver\n",
        "from physicsnemo.sym.domain import Domain\n",
        "from physicsnemo.sym.geometry.primitives_2d import Rectangle\n",
        "from physicsnemo.sym.domain.constraint import (\n",
        "    PointwiseBoundaryConstraint,\n",
        "    PointwiseInteriorConstraint,\n",
        ")\n",
        "from physicsnemo.sym.domain.validator import PointwiseValidator\n",
        "from physicsnemo.sym.key import Key\n",
        "from physicsnemo.sym.eq.pde import PDE\n",
        "from physicsnemo.sym.utils.io import ValidatorPlotter\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We import `Rectangle` from the 2D geometry module to define our square domain. The `PDE` base class allows us to define the p-Laplacian symbolically. The `Key` class is used to specify input/output variables for the neural network, and importantly, `p` is included as an input key so a single network learns solutions across all values of $p$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Step 1: Creating the geometry\n",
        "\n",
        "We create a 2D rectangular domain $[-1, 1] \\times [-1, 1]$ using the `Rectangle` class. PhysicsNeMo's geometry module also provides circles, triangles, and other shapes for more complex domains."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "```python\n",
        "geo = Rectangle((-1.0, -1.0), (1.0, 1.0))\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Step 2: Defining the p-Laplacian PDE\n",
        "\n",
        "We define the p-Laplacian PDE by inheriting from the `PDE` class. The key idea is to treat $p$ as a **symbolic variable** so that the neural network learns a family of solutions parameterized by $p$.\n",
        "\n",
        "The normalized p-Laplacian residual is:\n",
        "\n",
        "$$(p-1) u_x^2 u_{xx} + (p-1) u_y^2 u_{yy} + 2(p-2) u_x u_y u_{xy} + u_x^2 u_{yy} + u_y^2 u_{xx} = 0$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "```python\n",
        "class PLaplacian(PDE):\n",
        "    name = \"PLaplacian\"\n",
        "\n",
        "    def __init__(self):\n",
        "        x = Symbol(\"x\")\n",
        "        y = Symbol(\"y\")\n",
        "        p = Symbol(\"p\")\n",
        "\n",
        "        input_variables = {\"x\": x, \"y\": y, \"p\": p}\n",
        "\n",
        "        u = Function(\"u\")(*input_variables)\n",
        "\n",
        "        u_x = u.diff(x)\n",
        "        u_y = u.diff(y)\n",
        "        u_xx = u.diff(x, x)\n",
        "        u_yy = u.diff(y, y)\n",
        "        u_xy = u.diff(x, y)\n",
        "\n",
        "        p_laplacian = (\n",
        "            (p - 1) * u_x**2 * u_xx\n",
        "            + (p - 1) * u_y**2 * u_yy\n",
        "            + 2 * (p - 2) * u_x * u_y * u_xy\n",
        "            + u_x**2 * u_yy\n",
        "            + u_y**2 * u_xx\n",
        "        )\n",
        "\n",
        "        self.equations = {}\n",
        "        self.equations[\"p_laplacian\"] = p_laplacian\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We defined `x`, `y`, and `p` as SymPy symbols and declared `u` as a function of all three. PhysicsNeMo's symbolic differentiation then computes all the required partial derivatives (`u_x`, `u_y`, `u_xx`, `u_yy`, `u_xy`) automatically. The residual expression is stored in `self.equations[\"p_laplacian\"]`, and setting it to zero in the interior constraint enforces the PDE."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Creating the Neural Network nodes\n",
        "\n",
        "We use a `FullyConnectedArch` with three inputs (`x`, `y`, `p`) and one output (`u`). The network architecture is configured via the Hydra config file. The nodes list combines the PDE nodes (which compute derivatives and the PDE residual) with the network node."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "```python\n",
        "@physicsnemo.sym.main(config_path=\"conf\", config_name=\"config\")\n",
        "def run(cfg: PhysicsNeMoConfig) -> None:\n",
        "    p_lap = PLaplacian()\n",
        "\n",
        "    net = instantiate_arch(\n",
        "        input_keys=[Key(\"x\"), Key(\"y\"), Key(\"p\")],\n",
        "        output_keys=[Key(\"u\")],\n",
        "        cfg=cfg.arch.fully_connected,\n",
        "    )\n",
        "\n",
        "    nodes = p_lap.make_nodes() + [net.make_node(name=\"p_laplacian_network\")]\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Step 3: Setting up the Domain and constraints\n",
        "\n",
        "We create a `Domain` and add two types of constraints:\n",
        "\n",
        "1. **Boundary constraint (BC):** Enforce $u = |x|^{4/3} - |y|^{4/3}$ on the boundary of the square\n",
        "2. **Interior constraint:** Enforce the p-Laplacian residual $= 0$ inside the domain\n",
        "\n",
        "Both constraints are parameterized over $p \\in [2, 10]$, sampled uniformly during training."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "```python\n",
        "    x_sym = Symbol(\"x\")\n",
        "    y_sym = Symbol(\"y\")\n",
        "    p_sym = Symbol(\"p\")\n",
        "    sdf_sym = Symbol(\"sdf\")\n",
        "\n",
        "    p_range = {\n",
        "        p_sym: lambda batch_size: np.random.uniform(2, 10, (batch_size, 1))\n",
        "    }\n",
        "\n",
        "    domain = Domain()\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Boundary Constraint:** The Aronsson solution $u = |x|^{4/3} - |y|^{4/3}$ is used as the Dirichlet boundary condition. This is expressed symbolically using SymPy's `Abs` and `Rational`.\n",
        "\n",
        "**Interior Constraint:** The PDE residual `p_laplacian` is set to zero. We apply a weighting scheme:\n",
        "- **SDF weighting** (`sdf`): Reduces the PDE loss contribution near the boundary where the boundary condition dominates.\n",
        "- **Axis weighting** ($\\sqrt{x^2 + \\epsilon^2} \\cdot \\sqrt{y^2 + \\epsilon^2}$): Reduces influence near $x=0$ and $y=0$ where the Aronsson solution has singular gradients ($|x|^{4/3}$ is not smooth at the origin)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "```python\n",
        "    exact_bc = Abs(x_sym)**Rational(4, 3) - Abs(y_sym)**Rational(4, 3)\n",
        "\n",
        "    BC = PointwiseBoundaryConstraint(\n",
        "        nodes=nodes,\n",
        "        geometry=geo,\n",
        "        outvar={\"u\": exact_bc},\n",
        "        lambda_weighting={\"u\": 1.0},\n",
        "        batch_size=cfg.batch_size.BC,\n",
        "        parameterization=p_range,\n",
        "    )\n",
        "    domain.add_constraint(BC, \"BC\")\n",
        "\n",
        "    eps = 0.01\n",
        "    dist_x = sqrt(x_sym**2 + eps**2)\n",
        "    dist_y = sqrt(y_sym**2 + eps**2)\n",
        "    axis_weight = dist_x * dist_y\n",
        "\n",
        "    interior = PointwiseInteriorConstraint(\n",
        "        nodes=nodes,\n",
        "        geometry=geo,\n",
        "        outvar={\"p_laplacian\": 0},\n",
        "        batch_size=cfg.batch_size.interior,\n",
        "        lambda_weighting={\n",
        "            \"p_laplacian\": sdf_sym * axis_weight,\n",
        "        },\n",
        "        parameterization=p_range,\n",
        "    )\n",
        "    domain.add_constraint(interior, \"interior\")\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Step 4: Adding Validation data\n",
        "\n",
        "We create validation datasets for $p = 2, 5, 10$. For each value of $p$, we evaluate the network on a $50 \\times 50$ grid over the domain and compare against the Aronsson solution.\n",
        "\n",
        "Since the exact solution for finite $p$ is not known analytically, the Aronsson solution (exact for $p \\to \\infty$) serves as a reference. The comparison becomes more accurate as $p$ increases."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "```python\n",
        "    n_val = 50\n",
        "    x_vals = np.linspace(-0.98, 0.98, n_val)\n",
        "    y_vals = np.linspace(-0.98, 0.98, n_val)\n",
        "    X, Y = np.meshgrid(x_vals, y_vals)\n",
        "    X = np.expand_dims(X.flatten(), axis=-1)\n",
        "    Y = np.expand_dims(Y.flatten(), axis=-1)\n",
        "\n",
        "    u_exact = np.abs(X)**(4/3) - np.abs(Y)**(4/3)\n",
        "\n",
        "    for p_val in [2, 5, 10]:\n",
        "        P_test = np.full_like(X, float(p_val))\n",
        "        invar_p = {\"x\": X, \"y\": Y, \"p\": P_test}\n",
        "        validator_p = PointwiseValidator(\n",
        "            nodes=nodes,\n",
        "            invar=invar_p,\n",
        "            true_outvar={\"u\": u_exact},\n",
        "            batch_size=128,\n",
        "            plotter=ValidatorPlotter(),\n",
        "        )\n",
        "        domain.add_validator(validator_p, f\"validation_p{p_val}\")\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Step 5: Hydra configuration\n",
        "\n",
        "PhysicsNeMo uses Hydra for configuration management. The config file below defines the optimizer, scheduler, loss function, network architecture, training parameters, and batch sizes. Notable choices:\n",
        "\n",
        "- **ReLoBRaLo loss:** An adaptive loss balancing scheme that automatically adjusts the relative weighting of different loss terms during training.\n",
        "- **5-layer, 64-node MLP:** A compact network suitable for this parameterized problem.\n",
        "- **50,000 training steps** with validation every 2,000 steps."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "```yaml\n",
        "defaults:\n",
        "  - physicsnemo_default\n",
        "  - arch:\n",
        "      - fully_connected\n",
        "  - scheduler: tf_exponential_lr\n",
        "  - optimizer: adam\n",
        "  - loss: relobralo\n",
        "  - _self_\n",
        "\n",
        "custom:\n",
        "  p_min: 2.0\n",
        "  p_max: 10.0\n",
        "  p_validation: 10.0\n",
        "\n",
        "save_filetypes: \"vtk,npz\"\n",
        "\n",
        "scheduler:\n",
        "  decay_rate: 0.95\n",
        "  decay_steps: 2000\n",
        "\n",
        "loss:\n",
        "  alpha: 0.95\n",
        "  beta: 0.99\n",
        "  tau: 1.0\n",
        "  eps: 1.0e-08\n",
        "\n",
        "training:\n",
        "  max_steps: 50000\n",
        "  rec_results_freq: 2000\n",
        "  rec_validation_freq: 2000\n",
        "  rec_inference_freq: 2000\n",
        "  rec_monitor_freq: 200\n",
        "  rec_constraint_freq: 2000\n",
        "  save_network_freq: 5000\n",
        "  print_stats_freq: 200\n",
        "  summary_freq: 200\n",
        "\n",
        "batch_size:\n",
        "  BC: 512\n",
        "  interior: 2000\n",
        "\n",
        "arch:\n",
        "  fully_connected:\n",
        "    layer_size: 64\n",
        "    nr_layers: 5\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Step 6: Solver and training\n",
        "\n",
        "We create the solver using the domain and Hydra configuration, then call `solve()` to start training. PhysicsNeMo handles the training loop, logging, checkpointing, and validation automatically."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "```python\n",
        "    slv = Solver(cfg, domain)\n",
        "    slv.solve()\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    run()\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We are now ready to train the p-Laplacian solver. Since PhysicsNeMo uses Hydra for config management, we run the training as a Python script. The cell below executes `plap.py`.\n",
        "\n",
        "You can monitor training progress with TensorBoard:\n",
        "\n",
        "```\n",
        "tensorboard --logdir outputs/ --port 8889\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ[\"RANK\"] = \"0\"\n",
        "os.environ[\"WORLD_SIZE\"] = \"1\"\n",
        "os.environ[\"MASTER_ADDR\"] = \"localhost\" "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!python3 plap.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Visualizing the solution\n",
        "\n",
        "PhysicsNeMo saves validation results as `.npz` and `.vtp` files in the `outputs/` directory. Below we load the validation data for each $p$ value and create comparison plots showing the predicted solution, the Aronsson reference, and the error."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "import os\n",
        "\n",
        "plt.rcParams['image.cmap'] = 'jet'\n",
        "\n",
        "def aronsson_exact(x, y):\n",
        "    return np.abs(x)**(4/3) - np.abs(y)**(4/3)\n",
        "\n",
        "# --- Load validation data ---\n",
        "validator_dir = os.path.join(\"outputs\", \"p_laplacian_aronsson\", \"validators\")\n",
        "p_values = [2, 5, 10]\n",
        "all_data = {}\n",
        "\n",
        "for p_val in p_values:\n",
        "    npz_path = os.path.join(validator_dir, f\"validation_p{p_val}.npz\")\n",
        "    raw = np.load(npz_path, allow_pickle=True)\n",
        "    all_data[p_val] = np.atleast_1d(raw.f.arr_0)[0]\n",
        "    print(f\"Loaded p={p_val}\")\n",
        "\n",
        "# --- Individual validation plots (Predicted / True / Error) ---\n",
        "for p_val, data in all_data.items():\n",
        "    x = data['x'].flatten()\n",
        "    y = data['y'].flatten()\n",
        "    u_pred = data['pred_u'].flatten()\n",
        "    u_true = data['true_u'].flatten()\n",
        "\n",
        "    n_side = int(np.sqrt(len(x)))\n",
        "    idx = np.lexsort((x, y))\n",
        "    xg = x[idx].reshape(n_side, n_side)\n",
        "    yg = y[idx].reshape(n_side, n_side)\n",
        "    up = u_pred[idx].reshape(n_side, n_side)\n",
        "    ut = u_true[idx].reshape(n_side, n_side)\n",
        "    error = up - ut\n",
        "    rmse = np.sqrt(np.mean(error**2))\n",
        "    max_err = np.max(np.abs(error))\n",
        "\n",
        "    fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
        "\n",
        "    im0 = axes[0].pcolormesh(xg, yg, up, shading='auto', cmap='jet')\n",
        "    axes[0].set_title(f'Predicted u (p={p_val})')\n",
        "    plt.colorbar(im0, ax=axes[0], fraction=0.046)\n",
        "\n",
        "    im1 = axes[1].pcolormesh(xg, yg, ut, shading='auto', cmap='jet')\n",
        "    axes[1].set_title('True u (Aronsson)')\n",
        "    plt.colorbar(im1, ax=axes[1], fraction=0.046)\n",
        "\n",
        "    im2 = axes[2].pcolormesh(xg, yg, error, shading='auto',\n",
        "                              cmap='RdBu_r', vmin=-max_err, vmax=max_err)\n",
        "    axes[2].set_title(f'Error (RMSE={rmse:.4e})')\n",
        "    plt.colorbar(im2, ax=axes[2], fraction=0.046)\n",
        "\n",
        "    for ax in axes:\n",
        "        ax.set_xlabel('x')\n",
        "        ax.set_ylabel('y')\n",
        "        ax.set_aspect('equal')\n",
        "\n",
        "    plt.suptitle(f'p-Laplacian Validation: p = {p_val}', fontsize=14)\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(f\"validation_p{p_val}.png\", dpi=150, bbox_inches='tight')\n",
        "    plt.show()\n",
        "\n",
        "# --- Summary comparison plot (2D contour + 3D surface) ---\n",
        "n_cols = len(all_data) + 1\n",
        "fig = plt.figure(figsize=(4 * n_cols, 8))\n",
        "\n",
        "first_data = list(all_data.values())[0]\n",
        "x0 = first_data['x'].flatten()\n",
        "y0 = first_data['y'].flatten()\n",
        "u_exact_all = aronsson_exact(x0, y0)\n",
        "\n",
        "n_side = int(np.sqrt(len(x0)))\n",
        "idx = np.lexsort((x0, y0))\n",
        "xg = x0[idx].reshape(n_side, n_side)\n",
        "yg = y0[idx].reshape(n_side, n_side)\n",
        "u_exact_grid = u_exact_all[idx].reshape(n_side, n_side)\n",
        "\n",
        "all_u = [d['pred_u'].flatten() for d in all_data.values()]\n",
        "all_u.append(u_exact_all)\n",
        "vmin = min(np.min(u) for u in all_u)\n",
        "vmax = max(np.max(u) for u in all_u)\n",
        "\n",
        "# Row 1: 2D contour\n",
        "for i, (p_val, data) in enumerate(sorted(all_data.items())):\n",
        "    ax = fig.add_subplot(2, n_cols, i + 1)\n",
        "    u_pred = data['pred_u'].flatten()\n",
        "    err = u_pred - data['true_u'].flatten()\n",
        "    rmse = np.sqrt(np.mean(err**2))\n",
        "    ug = u_pred[idx].reshape(n_side, n_side)\n",
        "    im = ax.pcolormesh(xg, yg, ug, shading='auto', cmap='jet', vmin=vmin, vmax=vmax)\n",
        "    ax.set_title(f'p={p_val}, RMSE={rmse:.2e}', fontsize=10)\n",
        "    ax.set_xlabel('x'); ax.set_ylabel('y'); ax.set_aspect('equal')\n",
        "    plt.colorbar(im, ax=ax, fraction=0.046)\n",
        "\n",
        "ax_exact = fig.add_subplot(2, n_cols, len(all_data) + 1)\n",
        "im = ax_exact.pcolormesh(xg, yg, u_exact_grid, shading='auto', cmap='jet', vmin=vmin, vmax=vmax)\n",
        "ax_exact.set_title(r'Exact ($\\infty$-Lap)', fontsize=10)\n",
        "ax_exact.set_xlabel('x'); ax_exact.set_ylabel('y'); ax_exact.set_aspect('equal')\n",
        "plt.colorbar(im, ax=ax_exact, fraction=0.046)\n",
        "\n",
        "# Row 2: 3D surface\n",
        "for i, (p_val, data) in enumerate(sorted(all_data.items())):\n",
        "    ax3d = fig.add_subplot(2, n_cols, n_cols + i + 1, projection='3d')\n",
        "    ug = data['pred_u'].flatten()[idx].reshape(n_side, n_side)\n",
        "    ax3d.plot_surface(xg, yg, ug, cmap='jet', vmin=vmin, vmax=vmax,\n",
        "                      linewidth=0, antialiased=True)\n",
        "    ax3d.set_xlabel('x'); ax3d.set_ylabel('y'); ax3d.set_zlabel('u')\n",
        "    ax3d.set_title(f'p={p_val}', fontsize=10)\n",
        "    ax3d.view_init(elev=25, azim=-60)\n",
        "\n",
        "ax3d_exact = fig.add_subplot(2, n_cols, 2 * n_cols, projection='3d')\n",
        "ax3d_exact.plot_surface(xg, yg, u_exact_grid, cmap='jet', vmin=vmin, vmax=vmax,\n",
        "                        linewidth=0, antialiased=True)\n",
        "ax3d_exact.set_xlabel('x'); ax3d_exact.set_ylabel('y'); ax3d_exact.set_zlabel('u')\n",
        "ax3d_exact.set_title(r'Exact ($\\infty$-Lap)', fontsize=10)\n",
        "ax3d_exact.view_init(elev=25, azim=-60)\n",
        "\n",
        "plt.suptitle('p-Laplacian: Comparison Across p Values', fontsize=14)\n",
        "plt.tight_layout()\n",
        "plt.savefig(\"summary_comparison.png\", dpi=150, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "print(\"Done plotting.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We have now trained and visualized the p-Laplacian equation using PINNs with PhysicsNeMo. The network learns a **family of solutions** parameterized by $p$, allowing us to evaluate the solution at any value of $p$ within the training range without retraining.\n",
        "\n",
        "As $p$ increases, the solution should converge toward the Aronsson solution $u(x,y) = |x|^{4/3} - |y|^{4/3}$, which is the exact infinity-Laplacian solution."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
